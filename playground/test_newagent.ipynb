{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "openagent_dir = os.path.dirname(os.path.abspath(\"\"))\n",
    "sys.path.append(openagent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openagent import compiler\n",
    "from openagent.agent.completion import TextCompletionAgent\n",
    "from openagent.agent.chat import ChatAgent\n",
    "\n",
    "from openagent.llms._openai import OpenAI\n",
    "from openagent.vectorstores.chroma import Chroma\n",
    "from openagent.text_splitter import CharacterTextSplitter\n",
    "from openagent.knowledgebase.document_loaders.file.base import SimpleDirectoryReader\n",
    "from openagent.knowledgebase.doc_loader import document_loader\n",
    "\n",
    "from openagent.knowledgebase.base import SimpleKnowledgeBase\n",
    "from openagent.vectorstores.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# load .env file in format :\n",
    "# OPENAI_API_KEY=sk-xxx\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llmcc = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "llmtc = OpenAI(\n",
    "    model=\"text-davinci-003\"\n",
    ")\n",
    "\n",
    "SimpleDirectoryReader = document_loader('file_directory')\n",
    "\n",
    "reader = SimpleDirectoryReader('test_data/meteoric')\n",
    "raw_docs = reader.load_data()\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_overlap=40, chunk_size=1024)\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings()\n",
    "chroma = Chroma(embedding_function=openai_embeddings)    \n",
    "\n",
    "knowledge = SimpleKnowledgeBase(raw_data=raw_docs, data_transformer=splitter, vector_store=chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first thing Alex said to Xarnak was, \"I am no longer the scared child you remember, Xarnak. I am the protector of this planet, and I won't let you harm it.\"\n"
     ]
    }
   ],
   "source": [
    "# chat agent testing with knowledge\n",
    "\n",
    "chat_template = '''\n",
    "            {{#user~}}\n",
    "            You will use this FORMAT only to answer user's QUERY\n",
    "            FORMAT: {{format}}\n",
    "            QUERY: {{input}}\n",
    "\n",
    "            Use the below knowledge to answer QUERY in given FORMAT:-\n",
    "            {{RETRIEVED_KNOWLEDGE}}\n",
    "            {{~/user}}\n",
    "                                        \n",
    "            {{#assistant~}}\n",
    "            Yes, I will tell you about with that\n",
    "            {{~/assistant}}\n",
    "        \n",
    "            {{#user~}}\n",
    "            Yes, tell me\n",
    "            {{~/user}}\n",
    "                                        \n",
    "            {{#assistant~}}\n",
    "            {{gen 'response' temperature=0 max_tokens=300}}\n",
    "            {{~/assistant}}'''\n",
    "\n",
    "\n",
    "agent = ChatAgent(\n",
    "    llm = llmcc,\n",
    "    prompt_template = chat_template,\n",
    "    input_variables = {\"knowledge_variable\": 'input', \"extras\": 'format'},\n",
    "    knowledgebase = knowledge,\n",
    "    output_key='response'\n",
    "    )\n",
    "\n",
    "out = agent.run(input = \"What was the first thing Alex said to Xarnak?\", format = \"JSON\")\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.export_agent_config(\"test-agent-config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.knowledgebase.vector_store._embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "City: \"New Delhi\"\n",
      "Average temperature (C): \"25.5\"\"\n",
      "Population: \"2 crore\"\n",
      "Famous for (in 10 words):  \"Historical monuments, cuisine, markets\"\n"
     ]
    }
   ],
   "source": [
    "# formatted output with text completion model without knowledge base\n",
    "\n",
    "text_template = '''\n",
    "City: \"{{city}}\"\n",
    "Average temperature (C): \"{{gen 'avg_temp'}}\"\n",
    "Population: \"{{population}}\"\n",
    "Famous for (in 10 words): {{gen \"famous_for\" temperature=0.7 max_tokens=30}}'''\n",
    "\n",
    "agent = TextCompletionAgent(\n",
    "    llm=llmtc,\n",
    "    prompt_template = text_template,\n",
    "    return_complete=True,\n",
    "    input_variables={'extras': ['city', 'population']}\n",
    "    )\n",
    "\n",
    "out = agent.run(city = 'New Delhi', population = \"2 crore\")\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QnA with text completion model on knowledge base\n",
    "\n",
    "text_template = '''\n",
    "Here is a part of a movie script:\n",
    "{{RETRIEVED_KNOWLEDGE}}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer: {{gen 'answer'}}\n",
    "'''\n",
    "\n",
    "agent = TextCompletionAgent(\n",
    "    llm = llmtc,\n",
    "    prompt_template = text_template,\n",
    "    input_variables = {\"knowledge_variable\": 'question'},\n",
    "    knowledgebase = knowledge,\n",
    "    output_key='answer'\n",
    "    )\n",
    "\n",
    "out = agent.run(question = \"What is the name of the hero in the movie?\")\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "powerful that they were able to unite the world under the banner of hope, compassion, and solidarity.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# text completion with text completion model\n",
    "\n",
    "text_template = '''\n",
    "Here is one part of a movie script:\n",
    "{{RETRIEVED_KNOWLEDGE}}\n",
    "\n",
    "{{input}} {{gen 'complete'}}\n",
    "'''\n",
    "\n",
    "agent = TextCompletionAgent(\n",
    "    llm = llmtc,\n",
    "    prompt_template = text_template,\n",
    "    input_variables = {\"knowledge_variable\": 'input'},\n",
    "    knowledgebase = knowledge,\n",
    "    output_key='complete'\n",
    "    )\n",
    "\n",
    "out = agent.run(input = \"The hero of this movie was so \")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
